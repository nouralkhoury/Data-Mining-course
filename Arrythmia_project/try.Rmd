---
title: "Arrythmia"
author: "Nour Al Khoury"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    toc: true
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---








```{r LOADING DATA, warning=F, error=F, echo=F, message=F}
  library(readxl)
  library(knitr)
  library(kableExtra)
  library(glmnet)
  library(formattable)
  library(dplyr)
  library(ggplot2)
  library(plotly)
  library(reshape2)
  library(glmnet)
  library(crossval)
  library(boot)
  library(plm)
  library(klaR)
  library(DescTools)
  library(MASS)
```
  
```{r}
exam=as.data.frame(read_excel("Desktop/arrhythmia.xlsx", na="?"))
data=exam
set.seed(1)
```
  
# Data Preprocessing
  
```{r}
dim(data)
```
  
```{r}
which(duplicated(colnames(data)))
```
  
```{r echo=F}
  # converting the neccessary columns to categorical 
  nominal=c(2, 22:27, 34:39, 46:51, 58:63, 70:75, 82:87, 94:99, 106:111, 118:123, 130:135, 142:147, 154:159,280)
  for(i in nominal){
  data[,i]=as.factor(data[,i])
  }
```
  
  
```{r echo=F, message=F, warning=F, error=F}
  p <- data%>%
  group_by(class) %>%
  summarize(count = n()) %>%
  plot_ly(labels = ~class, values = ~count) %>%
  add_pie(hole = 0.6) %>%
  layout(title = "Class distribution.",  showlegend = F,
  xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
  yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
  
  p
```

  
```{r echo=F}
  binomial=data
  binomial$binomialClass= 0  # normal 
  binomial$binomialClass[which(binomial$class!=1)] =1
  binomial$class <- binomial$binomialClass
  binomial$binomialClass <- NULL
  binomial$class=as.factor(binomial$class)
  
  data[,"class"] <- as.numeric(as.character(data$class))
  binomial <- data
  binomial[which(data[,"class"] != 1), "class"] = 0
  data$class <- as.factor(data$class)
  binomial$class <- as.factor(binomial$class)
  
  
  class14=which(data$class==14)
  class7=which(data$class==7)
  class8=which(data$class==8)
  class9=which(data$class==9)
  class15=which(data$class==15)
  data=data[-c(class14,class7, class8,class15, class9),]
  data=droplevels(data)
  
  rm(class14, class15, class7, class8)
```
  

# Outliers
```{r echo=F, warning=F, message=F }
  namesss=colnames(data)[c(1,3,4)]
dat.m <- melt(data,id.vars='class', measure.vars=namesss)
boxplots <- ggplot(dat.m) +
geom_boxplot(aes(x=class, y=value, color=variable)) +labs(title = "Outliers")
boxplots=ggplotly(boxplots)

boxplots

```
  
 
```{r echo=F}
  ages=which(data$age<=0 | data$age>110)
  weights= which(data$weight>280 | data$weight <50)
  heights= which(data$height>220 | data$height<150)
  rows=unique(c(ages, weights, heights))
  cols=cbind(rows,data$age[rows], data$weight[rows], data$height[rows])
  colnames(cols)=c("row","age", "weight", "height")
  cols=as.data.frame(cols)
  
  p=ggplot(cols)+
  geom_point(aes(x=row, y=age), color = "cyan")+
  geom_point(aes(x=row, y=height), color = "red")+
  geom_point(aes(x=row, y=weight), color = "purple")
  
  p=ggplotly(p)
  p
  rm(ages, weights, heights, rows, cols)
```
  
  
```{r echo=F}
  data=data[-c(138,307),]
  index=which(binomial$height>400)
  binomial=binomial[-index,]
  rm(index)
```
  
# Missing Values
```{r echo=F, warning=F, message=F, error=F }
  is_null <- function(data){
  nulls= as.data.frame(which(is.na(data), arr.ind = T))
  classs=c()
  for(i in 1:nrow(nulls)){
  belongto=data$class[nulls$row[i]]
  classs=c(classs,belongto)
  }
  nulls= cbind(nulls,classs)
  return(nulls)}
  
  nulls= is_null(data)
  pp= ggplot(nulls, aes(x=row, y=col)) + 
  geom_point(aes(size=2, colour=classs, text=paste("class:",classs)), alpha=0.4) +
  geom_text(aes(size=2, label=classs), colour="gray20", alpha=1) +
  labs(title = "NA distribution across classes",
  x = "row",
  y = "column")
  pp=ggplotly(pp)
  pp
  rm(pp, nulls)
```
  
  since the attribute at column 14 has a lot of missing values (>70%), it is best to remove it.
```{r echo=F}
  data=data[,-which(colnames(data)=="j")]
  binomial=binomial[,-which(colnames(binomial)=="j")]
```
  
  
  removing the columns that only have 1 value, it does not serve us anything
```{r}
  unnecessary <- function(data){
del=c()
for (i in 1:ncol(data)) {
t=length(table(data[,i]))
if(t<=1){
del=c(del,i)
}
}
return(del)
}


del=unnecessary(data)
if(length(del)!=0){
data=data[,-del]}

del=unnecessary(binomial)
if(length(del)!=0){
binomial= binomial[,-del]}
rm(del)
```


```{r}
# removing columns that have 90% of it's data the same. this is only done for the binomial data. 
remove.col = c()
for (i in 1:ncol(binomial))
{
  if(is.factor(binomial[,i]))
  {
    col1 = which(binomial[,i] == 1)
    if (length(col1) >= 0.9*NROW(binomial[,i]))
    {
      remove.col = c(remove.col, i)
    }else
    {
      col0 = which(binomial[,i] == 0)
      if(length(col0) >= 0.9*NROW(binomial[,i]))
      {
        remove.col = c(remove.col, i)
      }
    }
  }
}

if(length(remove.col)>=1){
binomial= binomial[, -remove.col]}


rm(col0, col1, i, remove.col)

```



```{r echo=F}
#getting only the categorical variables
categorical<- function(data){
  nom=names(which(sapply(data, function(x) is.factor(x))==T))
  nom=as.vector(nom)
  categ=c()
  for (i in 1:length(nom)) {
    categ=c(categ,which(colnames(data)==nom[i]))
  }
  return(categ)
}
```


```{r warning=FALSE, echo=F}
categ=categorical(data)
pvalues=rep(NA, ncol(data[,-categ]))
s=data[,-categ]
```


Replacing NA with the mean of the class they belong to 
```{r error=F, warning=FALSE}
replace_na <- function(data){
  for(col in 1:ncol(data)){
    list=which(is.na(data[,col]))
    if(!is.factor(data[,col])){ 
      if(length(list)>0){ 
        for (i in list) {
          classbelongs=data$class[i]
          classAV= mean(data[which(data$class==classbelongs),col], na.rm=T)
          data[i,col]=classAV
        }
      }
    }
  }
  return(data)
} 
data=replace_na(data)
binomial=replace_na(binomial)
```


```{r CORRELATION, warning=F, message=F, error=F}
# Dropping predictors with high correlations 
high_cor <- function(data){
  categ=categorical(data)
  correlation=cor(data[,-categ])
  index=FindCorr(correlation, cutoff = 0.8)
  highnames=colnames(correlation)[index]
  
  to.remove=c()
  for(i in 1:length(highnames)){
    to.remove=c(to.remove, which(colnames(data)==highnames[i]))
  }
  if(length(to.remove)!=0){
    data=data[,-to.remove]}
  return(data)
}

data=high_cor(data)
binomial= high_cor(binomial)
```

Correlation plot
```{r warning=F, message=F, fig.pos="h"}
library(gplots)
library(viridis)
par(mfrow=c(2,2))
categ=categorical(data)
heatmap.2(cor(data[,-categ]), dendrogram = "none", trace="none", col = viridis(10))
```


```{r Variance, message=FALSE, warning=FALSE}
#Removing predictos with a 0 standard deviation
vars=apply(data[,-categ], 2, var)

if(length(which(vars==0)==0)){
data=data[,-which(vars==0)]
}
```



# Model selection 

```{r, echo=F}
methods=matrix(NA, nrow=5,ncol=1)
methods[1,1]="Best Subset selection"
methods[2,1]="Forward selection"
methods[3,1]="Backward selection"
methods[4,1]="Ridge Regression"
methods[5,1]="Lasso"
colnames(methods)="Approaches"
methods %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover","responsive"),full_width = F) %>%
  row_spec(1:5, bold = T)

```


## Multinomial
we use stepclass() function to do the subset selection on a multiclass output.

### Subset Selection 

####  Best subset Selection 
number of predictors is large, this process becomes too extensive.<br>


Linear dependencies<br>
```{r}
categ=categorical(data)
suspiscious= detect.lindep(data[,-categ])

categ=categorical(binomial) 
suspiscious= detect.lindep(binomial[,-categ])

```

#### Forward
```{r FORWARDselection,error=F, message=FALSE, warning=FALSE, echo=F, cache=T}
set.seed(2)
forward.lda=stepclass(class~., "lda", data=data , direction="forward", improvement=0.001, folds=10, family="multinomial")

set.seed(2)
forward.qda=stepclass(class~., "qda", data=data , direction="forward", improvement=0.001, folds=10, family="multinomial")
```


#### Mixed Selection

Using stepclass() function, that can be performed on both lda and qda.

```{r BOTH selection, echo=F , warning=F, error=F, message=F}
set.seed(2)
both.lda= stepclass(class~., "lda", data=data, direction="both",folds=10, improvement=0.001 , family= binomial)

set.seed(2)
both.qda=stepclass(class~., "qda", data=data, direction="both",folds=10, improvement=0.001 , family= binomial)
```

Since the forward and mixed are giving the exact same predictors, i decided to use one of them. However, the backward approach will not be used because it included the full model with a very bad correctness rate. 
```{r echo=F}
par(mfrow=c(1,2))
plot(both.lda, main = "LDA Mixed Selection")
plot(forward.lda, main="LDA Forward Selection.")

par(mfrow=c(1,2))
plot(both.qda, main = "QDA Mixed Selection.")
plot(forward.qda, main="QDA Forward Selection.")
```


##### LDA model
```{r}
# set up lda prediction function
predfun.lda = function(train.x, train.y, test.x, test.y, negative)
{
  require("MASS") # for lda function
  
  lda.fit = lda(train.x, grouping=train.y)
  ynew = predict(lda.fit, test.x)$class
  
  # count TP, FP etc.
  out = confusionMatrix(test.y, ynew, negative=negative)
  print(out)
  return( mean(ynew == test.y) )
}

both.lda.predictor= strsplit(as.character(as.vector(both.lda$formula))," ")[[3]]
both.lda.predictor=both.lda.predictor[which(both.lda.predictor!="+")]
X = as.matrix(data[,both.lda.predictor, drop=FALSE]) 
Y = data$class 

set.seed(12345)
multi.lda.cv = crossval(predfun.lda, X, Y, K=7, B=1, negative="0")
```


##### QDA mode
```{r}
# setting up the qda predict function
predfun.qda = function(train.x, train.y, test.x, test.y, negative)
{
  require("MASS") # for lda function
  
  qda.fit = qda(train.x, grouping=train.y)
  ynew = predict(qda.fit, test.x)$class
  
  # count TP, FP etc.
  #out = confusionMatrix(test.y, ynew, negative=negative)

  return( mean(ynew == test.y))
}


X = as.matrix(data[,c("t_int" , "heart_rate" , "v1_nb_intr_defl" , "v4_nb_intr_defl" , 
    "v4_amp_jj_wave"), drop=FALSE]) 
Y = data$class  

set.seed(12345)
multi.qda.cv = crossval(predfun.qda, X, Y, K=7, B=1, negative="0")
```

### Shrinkage
```{r echo=F, warning=F, message=F}
#these classes should be removed because they have few observations.
set.seed(1)
x=model.matrix(data$class~.,data)[,-1]
y=data$class
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
lambdas <- 10^seq(2, -2, by = -.1)
```

#### Ridge
```{r error=F, message=FALSE, warning=FALSE}
set.seed(1)
ridge.cv=cv.glmnet(x[train,],y[train],alpha=0, family = "multinomial", lambda = lambdas, nfolds = 10, type.measure = "class")
```

```{r echo=F}
plot(ridge.cv)
```

lambda.mse1 = which would be the lambda that resulted in the simplest model (model with the fewest non-zero parameters) and was 1 standard error of the optimal lambda
```{r echo=F}
optimal_lamda=ridge.cv$lambda.min
optimal_lamda
par(mfrow=c(3,3))
plot(ridge.cv$glmnet.fit, "lambda")
```

rebuilding model with best lambda
```{r warning=F, message=F, error=F}
best.ridge=glmnet(x[train,],y[train],alpha = 0, lambda = optimal_lamda,"multinomial")
```

```{r error=F, warning=F, message=F}
ridge.pred=predict(best.ridge, s=optimal_lamda, newx = x[test,], type="class")
table(as.vector(ridge.pred), y[test])
ridge.accuracy=mean(ridge.pred==y[test])

c=coef(ridge.cv,s=ridge.cv$lambda.min, exact=T)
index=which(c$`1`!=0)
variables=row.names(c$`1`)[index]
```


```{r}
ridge.accuracy
```


#### LASSO

```{r HERE BABAY, error=F, message=FALSE, warning=FALSE}
set.seed(1234)
lasso.cv=cv.glmnet(x[train,],y[train],alpha =1,lambda=lambdas, family = "multinomial", type.measure="class")
```

```{r echo=F}
plot(lasso.cv)
```


```{r echo=F}
set.seed(1234)
lass.best=lasso.cv$glmnet.fit
bestlam =lasso.cv$lambda.1se
lasso.pred=predict(lasso.cv,s=bestlam,newx=x[test,], type="class")
lasso.accuracy=mean(lasso.pred==y[test])
c=coef(lasso.cv,s=lasso.cv$lambda.min, exact=T)
index=which(c$`1`!=0)
variables=row.names(c$`1`)[index]
```

```{r}
lasso.accuracy
```


```{r echo=F}
par(mfrow=c(3,3))
plot(lasso.cv$glmnet.fit, "lambda", label = T)
```



## Binomial 

### Subset Selection

#### GLM
```{r STEP GLM, error=F, message=FALSE, warning=FALSE, results="hide"}
set.seed(1234)
library(stats)
logist= glm(class~., data=binomial,family = "binomial")
binary.both=step(logist, direction = "both")

binary_both_variables=names(binary.both$coefficients)

glm1= glm(binary.both$formula, data=binomial, family = "binomial")

#removing the variable with high VIF shifted the accuracy drastically.
VIF(glm1)[1:20]
```



```{r warning=F, message=F, error=F}
#accuracy when predicting if the patient has arrythmia
set.seed(1234)
glm.cv= cv.glm(glm1,data=binomial)
glm.acc=1-glm.cv$delta[1]


## my cross validation
set.seed(1234)
k=10
shuffled= binomial[sample(nrow(binomial)),]

# split the data into k folds
folds= cut(seq(1,nrow(shuffled)),breaks = k, labels = F)

#perform the kfold cv
acc=rep(0,k)
for(i in 1:k){
  # segment our data by fold 
  train=which(folds!=i, arr.ind = T)
  testdata= shuffled[-train,]
  
  models= glm(binary.both$formula, data = shuffled, subset = train, family = "binomial")
  class.p=rep(0,nrow(binomial[-train,]))
  predic=  predict(models, testdata)
  ok=which(predic>0.5)
  class.p[ok]=1
  table(class.p, binomial$class[-train])
  acc[i]=mean((testdata$class == class.p))
}

mycv.acc=mean(acc)

```

#### LDA
```{r or here, cache=T, warning=F, message=F, error=F}
set.seed(1234)
binary.lda= stepclass(class~., "lda", data=binomial , direction="forward", improvement=0.001, folds=10, family="binomial")
```

### Fitting the LDA model

```{r there ,message=F, warning=F, error=F}

binary.lda.predictor= strsplit(as.character(as.vector(binary.lda$formula))," ")[[3]]
binary.lda.predictor=binary.lda.predictor[which(binary.lda.predictor!="+")]
X = as.matrix(binomial[,binary.lda.predictor, drop=FALSE]) 
Y = binomial$class

set.seed(1234)
bino.lda.cv = crossval(predfun.lda, X, Y, K=10, B=1, negative="0")
```

```{r}
bino.lda.cv$stat
```

#### QDA
```{r  cache=T, warning=F, message=F, error=F}
set.seed(2)
binary.qda= stepclass(class~., "qda", data=binomial, direction="forward", improvement=0.001, folds=10, family="binomial")

```

### Fitting the QDA mode<br>
```{r zer ,warning=F, error=F, message=F}
binary.qda.predictor= strsplit(as.character(as.vector(binary.qda$formula))," ")[[3]]
binary.qda.predictor=binary.qda.predictor[which(binary.qda.predictor!="+")]
X = as.matrix(binomial[,binary.qda.predictor, drop=FALSE]) 
Y = binomial$class  

set.seed(2)
bino.qda.cv = crossval(predfun.qda, X, Y, K=10, B=1, negative="0")
```

```{r}
bino.qda.cv$stat
```


### Shrinkage

#### Ridge

```{r echo=F, warning=F, message=F}
#these classes should be removed because they have few observations.
set.seed(1)
x=model.matrix(binomial$class~., binomial)
y=binomial$class
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
lambdas <- 10^seq(2, -2, by = -.1)
```


```{r BUILDING RIDGE MODEL, error=F, message=FALSE, warning=FALSE}
set.seed(1)
bino.ridge.cv=cv.glmnet(x[train,],y[train],alpha=0, family = "binomial", lambda = lambdas, nfolds = 10, type.measure = "class")
```

```{r echo=F}
plot(bino.ridge.cv)
```

lambda.mse1 = which would be the lambda that resulted in the simplest model (model with the fewest non-zero parameters) and was 1 standard error of the optimal lambda<br>
```{r echo=F}
optimal_lamda=bino.ridge.cv$lambda.min
optimal_lamda
plot(bino.ridge.cv$glmnet.fit, "lambda")
```

rebuilding model with best lambda
```{r}
bino.best.ridge=glmnet(x[train,],y[train],alpha = 0, lambda = optimal_lamda,"multinomial")
```

```{r PREDICTING ,error=F, warning=F, message=F}
bino.ridge.pred=predict(bino.best.ridge, s=optimal_lamda, newx = x[test,], type="class")
bino.ridge.accuracy=mean(bino.ridge.pred==y[test])

c=coef(bino.ridge.cv,s=bino.ridge.cv$lambda.min, exact=T)
index=which(c!=0)
# these are the non-zero coef in lasso
variables=row.names(c)[index]
length(variables)
```

###Ridge full model
```{r}
bino.fullridge=glmnet(x,y,alpha=0, lambda=lambdas,family = "binomial")
predict(bino.fullridge, type="coefficients", s=optimal_lamda)[1:7]
```

Ridge Confusion Matrix<br>
```{r}
table(as.vector(bino.ridge.pred), y[test])
```

<br>
```{r}
bino.ridge.accuracy
```

#### LASSO
```{r error=F, message=FALSE, warning=FALSE}
set.seed(8)
bino.lasso.cv=cv.glmnet(x[train,],y[train],alpha =1,family = "binomial", type.measure="class")
```

```{r echo=F}
plot(bino.lasso.cv)
```


```{r echo=F}
set.seed(8)
bino.lasso.best=bino.lasso.cv$glmnet.fit
bestlam =bino.lasso.cv$lambda.1se
bino.lasso.pred=predict(bino.lasso.cv,s=bestlam,newx=x[test,], type="class")
bino.lasso.accuracy=mean(bino.lasso.pred==y[test])

# to get the lasso's coefficient for the best lambda that did not shrink to 0
c=coef(bino.lasso.cv,s=bino.lasso.cv$lambda.min, exact=T)
index=which(c!=0)
# these are the non-zero coef in lasso
variables=row.names(c)[index]
length(variables)
```

### Lasso Full model
```{r}
bino.fullasso=glmnet(x,y,alpha=1, lambda=lambdas,family = "binomial")
predict(bino.fullasso, type="coefficients", s=bestlam)[1:7]

```

```{r}
bino.lasso.accuracy
```


```{r echo=F}
par(mfrow=c(3,3))
plot(lasso.cv$glmnet.fit, "lambda", label = T)
```


## Binomial model accuracies
```{r error=F, echo=F,fig.pos="H"}
results=data.frame(NA)
results=cbind(results, c(glm.acc,bino.lda.cv$stat, bino.qda.cv$stat,bino.lasso.accuracy, bino.ridge.accuracy))
results=cbind(results, c("GLM","LDA", "QDA","LASSO", "RIDGE"))
colnames(results)=c("1","accuracy", "model")
results[,2:3] %>%
  mutate_if(is.numeric, function(x) {
    cell_spec(x, bold = T, 
              color = spec_color(x, end = 0.9),
              font_size = spec_font_size(x))
  }) %>%
  mutate(model = cell_spec(
    model, color = "white", bold = T,
    background = spec_color(1:5, end = 0.9, option = "A", direction = -1)
  )) %>%
  kable(escape = F, align = "c") %>%
  kable_styling(c("striped", "condensed"), full_width = F)
rm(results)
```

# Multinomial model accuracies
```{r error=F, echo=F,render=T,fig.pos="H"}
results=data.frame(NA)
results=cbind(results, c(multi.lda.cv$stat, multi.qda.cv$stat,lasso.accuracy, ridge.accuracy ))
results=cbind(results, c("LDA", "QDA","LASSO", "RIDGE"))
colnames(results)=c("1","accuracy", "model")
results[,2:3] %>%
  mutate_if(is.numeric, function(x) {
    cell_spec(x, bold = T, 
              color = spec_color(x, end = 0.9),
              font_size = spec_font_size(x))
  }) %>%
  mutate(model = cell_spec(
    model, color = "white", bold = T,
    background = spec_color(1:4, end = 0.9, option = "A", direction = -1)
  )) %>%
  kable(escape = F, align = "c") %>%
  kable_styling(c("striped", "condensed"), full_width = F)

```

```{r}
dim(data) #multi
dim(binomial)
```
# Conclusion

Almost all the model had an accuracy either equal or larger than the paper's (62%). 
Here, the glm model performed best with an accuracy around 77%. however, this model included a high number of predictors. An alternative would be, using the LDA or QDA models that had around 70-75% accuracy with few predictors(7-10).
For the multiclass, the lasso and the lda had 73% accuracy, however the lda had less predictors.
